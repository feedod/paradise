<!DOCTYPE html>
<html lang="ru">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,viewport-fit=cover" />
<title>LiquidGlass Companion</title>
<style>
  /* --- Base / Liquid Glass look --- */
  :root{
    --glass-bg: rgba(255,255,255,0.04);
    --accent: rgba(0,122,255,0.18);
    --text: #ffffff;
    --muted: rgba(255,255,255,0.6);
    --glass-border: rgba(255,255,255,0.06);
  }
  *{box-sizing:border-box;margin:0;padding:0}
  html,body{height:100%;width:100%;background:#000;overflow:hidden;font-family: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Helvetica,Arial; -webkit-font-smoothing:antialiased;}
  /* canvas covers whole screen, but pointer events disabled to avoid interaction */
  canvas{position:fixed;inset:0;width:100%;height:100%;z-index:1;display:block;pointer-events:none}
  /* Chat interface anchored bottom, full height usage */
  #chat-interface{
    position:fixed;
    inset:0 0 0 0;
    display:flex;
    flex-direction:column;
    justify-content:flex-end;
    align-items:center;
    padding:12px;
    z-index:2;
    pointer-events:auto;
    height:100%;
  }

  /* Messages container */
  #messages-wrap{
    width:min(680px,96%);
    max-height:65%;
    display:flex;
    flex-direction:column;
    gap:8px;
    align-self:center;
    pointer-events:auto;
  }
  /* hide messages list when empty */
  #messages-list{
    display:flex;
    flex-direction:column;
    gap:6px;
    overflow:hidden;
    padding:10px;
    border-radius:14px;
    /* Liquid glass panel */
    background: linear-gradient(180deg, rgba(255,255,255,0.02), rgba(255,255,255,0.01));
    backdrop-filter: blur(18px) saturate(160%);
    border:1px solid var(--glass-border);
    box-shadow: 0 6px 18px rgba(0,0,0,0.6);
    /* remove message background request: make bubbles transparent-ish */
  }
  #messages-list.empty{display:none}

  .message-bubble{
    max-width:75%;
    padding:8px 10px;
    border-radius:12px;
    font-size:13px; /* уменьшенный размер */
    line-height:1.2;
    color:var(--text);
    align-self:flex-start;
    background:transparent; /* убираем фон сообщений */
    border:1px solid transparent;
    word-break:break-word;
    display:flex;
    flex-direction:column;
    gap:6px;
    opacity:0;
    transform:translateY(6px);
    transition:all 260ms cubic-bezier(.2,.9,.2,1);
  }
  .message-bubble.animate{opacity:1;transform:none}
  .message-bubble.user{align-self:flex-end; border-color: rgba(0,122,255,0.18); background: linear-gradient(180deg, rgba(0,122,255,0.06), rgba(0,122,255,0.03));}
  .message-bubble.ai{align-self:flex-start; border-color: rgba(255,255,255,0.04); }
  .message-text{font-size:13px;color:var(--text);white-space:pre-wrap}
  .message-time{font-size:11px;color:var(--muted);align-self:flex-end;margin-top:4px}

  /* Input area */
  #input-container{
    width:min(680px,96%);
    display:flex;
    gap:10px;
    align-items:center;
    padding:10px;
    margin-top:10px;
    border-radius:14px;
    background: linear-gradient(180deg, rgba(255,255,255,0.02), rgba(255,255,255,0.01));
    backdrop-filter: blur(18px) saturate(160%);
    border:1px solid var(--glass-border);
  }
  #chat-input{
    flex:1;
    min-height:44px;
    border-radius:12px;
    border:1px solid rgba(255,255,255,0.04);
    padding:10px 12px;
    background: rgba(255,255,255,0.02);
    color:var(--text);
    font-size:15px;
    outline:none;
  }
  #chat-input::placeholder{color:rgba(255,255,255,0.4)}
  .icon-button{
    width:46px;height:46px;border-radius:50%;display:flex;align-items:center;justify-content:center;border:1px solid rgba(255,255,255,0.06);
    background:rgba(255,255,255,0.02);cursor:pointer;
    -webkit-tap-highlight-color: transparent;
  }
  .icon-button.disabled{opacity:0.35;pointer-events:none}
  /* mic listening animation improved */
  .mic-ring{
    position:relative;
    width:44px;height:44px;border-radius:50%;display:flex;align-items:center;justify-content:center;
  }
  .mic-ring .pulse{
    position:absolute;inset:0;border-radius:50%;transform:scale(1);opacity:0;transition:all 400ms ease;
    background: radial-gradient(circle at 50% 50%, rgba(0,122,255,0.24), rgba(0,122,255,0.06));
  }
  .listening .pulse{animation:micPulse 1400ms infinite ease-out}
  @keyframes micPulse{
    0%{transform:scale(1);opacity:0.6}
    70%{transform:scale(1.8);opacity:0}
    100%{transform:scale(1.8);opacity:0}
  }
  .mic-level{transition:transform 120ms linear}

  /* loading indicator centered and minimal */
  #loading-indicator{display:flex;align-items:center;justify-content:center;height:28px;gap:6px;}
  .dot{width:6px;height:6px;border-radius:50%;background:var(--text);opacity:0.12;animation:dotPulse 1s infinite}
  .dot:nth-child(1){animation-delay:0}
  .dot:nth-child(2){animation-delay:0.12s}
  .dot:nth-child(3){animation-delay:0.24s}
  @keyframes dotPulse{0%{opacity:.12;transform:scale(.8)}50%{opacity:1;transform:scale(1.25)}100%{opacity:.12;transform:scale(.8)}}

  /* small screens tweak */
  @media (max-width:520px){
    #messages-list{padding:8px;border-radius:12px}
    .message-bubble{font-size:13px;padding:8px;max-width:86%}
    #chat-input{font-size:15px}
  }
</style>
</head>
<body>
  <canvas id="three-canvas" aria-hidden="true"></canvas>

  <div id="chat-interface" role="application" aria-label="Chat companion">
    <div id="messages-wrap">
      <div id="messages-list" class="empty" aria-live="polite"></div>
    </div>

    <div id="input-container" role="region" aria-label="Controls">
      <input id="chat-input" type="text" inputmode="text" autocomplete="off" placeholder="Напишите сообщение..." />
      <button id="voice-button" class="icon-button" title="Голосовой ввод" aria-pressed="false" aria-label="Голосовой ввод">
        <div class="mic-ring" id="mic-ring">
          <div class="pulse"></div>
          <svg id="mic-svg" class="mic-level" width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="1.6">
            <path d="M12 14a3 3 0 0 0 3-3V6a3 3 0 0 0-6 0v5a3 3 0 0 0 3 3z"></path>
            <path d="M19 11v1a7 7 0 0 1-14 0v-1" stroke-linecap="round"></path>
            <path d="M12 19v3" stroke-linecap="round"></path>
          </svg>
        </div>
      </button>

      <button id="send-button" class="icon-button" title="Отправить" aria-label="Отправить">
        <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="1.6">
          <path d="M22 2L11 13"></path><path d="M22 2L15 22l-4-9-9-4 20-7z"></path>
        </svg>
      </button>
    </div>
  </div>

<script type="module">
/* ------------- THREE + VRM minimal import (CDN) ------------- */
/* Use latest stable three + three/examples modules. If offline, include local builds. */
import * as THREE from 'https://cdn.jsdelivr.net/npm/three@0.181.2/build/three.module.js';
import { GLTFLoader } from 'https://cdn.jsdelivr.net/npm/three@0.181.2/examples/jsm/loaders/GLTFLoader.js';
import { VRMLoaderPlugin, VRMUtils, VRMHumanBoneName } from 'https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@3.1.0/lib/three-vrm.module.js';

/* ---------------- Helper utils ---------------- */
const $ = id => document.getElementById(id);

class Companion {
  constructor(){
    // canvas + renderer
    this.canvas = $('three-canvas');
    this.renderer = new THREE.WebGLRenderer({canvas:this.canvas, alpha:true, antialias:true, powerPreference:'low-power' });
    // performance: limit pixel ratio
    this.renderer.setPixelRatio(Math.min(window.devicePixelRatio || 1, 1.25));
    this.renderer.setSize(window.innerWidth, window.innerHeight, false);
    this.renderer.outputColorSpace = THREE.SRGBColorSpace;
    this.scene = new THREE.Scene();
    this.camera = new THREE.PerspectiveCamera(32, window.innerWidth/window.innerHeight, 0.1, 1000);
    this.clock = new THREE.Clock();
    this.vrm = null;
    this.mixer = null;
    this.isRendering = false;
    this.animationFrame = null;
    this.lastRender = 0;
    this.minRenderInterval = 1000/30; // cap to 30fps to save battery
    this.messages = [];
    this.maxMessages = 5;

    // audio / speech
    this.speechSynth = window.speechSynthesis || null;
    this.currentUtterance = null;
    this.recognition = null;
    this.isListening = false;
    this.audioContext = null;
    this.analyser = null;
    this.micStream = null;
    this.micSilenceTimer = null;
    this.lastSoundTime = 0;

    // init
    this.setupScene();
    this.setupResize();
    this.setupChat();
    this.setupSpeechRecognition();
    this.initMicPermissionPrompt(); // ask mic permission on load
    this.start(); // start render loop
  }

  // ---------------- Scene / Model ----------------
  setupScene(){
    // camera
    this.camera.position.set(0, 1.45, 2.6);

    // lights (simple, cheap)
    const hemi = new THREE.HemisphereLight(0xffffff,0x222233,0.9);
    const dir = new THREE.DirectionalLight(0xfff8e8,0.6);
    dir.position.set(3,5,2);
    this.scene.add(hemi, dir);

    // disable pointer interactions on canvas to completely prevent drag/rotate
    this.canvas.style.pointerEvents = 'none';
  }

  async loadVRM(url){
    // simple loader: try-catch and minimal processing
    try{
      const loader = new GLTFLoader();
      loader.register(parser => new VRMLoaderPlugin(parser));
      const gltf = await loader.loadAsync(url);
      const vrm = gltf.userData.vrm;
      if(!vrm) throw new Error('VRM not found in glTF');
      this.vrm = vrm;
      // remove heavy geometry optimizations if needed, but keep simple cleanup
      try { VRMUtils.removeUnnecessaryJoints(vrm.scene); } catch(e){}
      this.scene.add(vrm.scene);
      this.centerModel(vrm.scene);
      // ensure arms down (опущены)
      this.setArmsDown();
      // expressions safe-guard: create mapping if missing
      this.setupExpressionSafeDefaults();
      // small idle mixer if animations exist
      if(gltf.animations && gltf.animations.length){
        this.mixer = new THREE.AnimationMixer(vrm.scene);
        gltf.animations.slice(0,1).forEach(clip => {
          const action = this.mixer.clipAction(clip);
          action.play();
          action.setEffectiveWeight(0.25); // reduce influence to save CPU
        });
      }
    }catch(err){
      console.warn('VRM load failed', err);
    }
  }
  centerModel(object){
    const box = new THREE.Box3().setFromObject(object, true);
    const center = box.getCenter(new THREE.Vector3());
    object.position.x -= center.x;
    object.position.y -= box.min.y; // sit on floor
    object.position.z -= center.z*0.2;
    // adjust camera based on size
    const size = box.getSize(new THREE.Vector3()).length();
    this.camera.position.set(0, Math.max(1.3, box.getSize(new THREE.Vector3()).y*0.9), size*0.8 + 0.8);
    this.camera.lookAt(0,1.4,0);
  }
  setArmsDown(){
    try{
      if(!this.vrm || !this.vrm.humanoid) return;
      const left = this.vrm.humanoid.getNormalizedBoneNode(VRMHumanBoneName.LeftUpperArm);
      const right = this.vrm.humanoid.getNormalizedBoneNode(VRMHumanBoneName.RightUpperArm);
      // gentle down position
      if(left) left.rotation.set(-Math.PI*0.15, 0, Math.PI*0.08);
      if(right) right.rotation.set(-Math.PI*0.15, 0, -Math.PI*0.08);
    }catch(e){}
  }
  setupExpressionSafeDefaults(){
    if(!this.vrm) return;
    if(!this.vrm.expressionManager) return;
    // ensure common expressions exist; if not, ignore quietly
    ['happy','neutral','surprised','blink','aa','ih','oh'].forEach(k=>{
      try{ this.vrm.expressionManager.setValue(k,0); }catch(e){}
    });
  }
  setEmotion(name, value=1.0){
    if(!this.vrm?.expressionManager) return;
    // map some friendly aliases
    const map = {
      'happy':'happy',
      'neutral':'neutral',
      'surprised':'surprised',
      'blink':'blink'
    };
    const key = map[name] || name;
    try{ this.vrm.expressionManager.setValue(key, value); }catch(e){}
  }

  // ---------------- Render loop with optimizations ----------------
  start(){
    if(this.isRendering) return;
    this.isRendering = true;
    const loop = (t) => {
      this.animationFrame = requestAnimationFrame(loop);
      const now = performance.now();
      if(now - this.lastRender < this.minRenderInterval) return; // throttle
      this.lastRender = now;
      const delta = Math.min(0.05, this.clock.getDelta());
      // cheap updates
      if(this.mixer) this.mixer.update(delta);
      if(this.vrm) {
        // reduce update frequency for VRM heavy ops
        try{ this.vrm.update(delta); }catch(e){}
      }
      this.renderer.render(this.scene, this.camera);
    };
    this.animationFrame = requestAnimationFrame(loop);
  }
  stop(){
    if(this.animationFrame) cancelAnimationFrame(this.animationFrame);
    this.isRendering = false;
    this.animationFrame = null;
  }
  setupResize(){
    const onResize = () => {
      const w = window.innerWidth, h = window.innerHeight;
      this.camera.aspect = w/h;
      this.camera.updateProjectionMatrix();
      this.renderer.setSize(w,h,false);
    };
    window.addEventListener('resize', onResize, {passive:true});
  }

  // ---------------- Chat UI ----------------
  setupChat(){
    this.msgList = $('messages-list');
    this.input = $('chat-input');
    this.voiceBtn = $('voice-button');
    this.sendBtn = $('send-button');

    // initial state
    this.sendBtn.addEventListener('click', ()=> this.handleSend());
    this.input.addEventListener('input', ()=> this.updateInputState());
    this.input.addEventListener('keydown', (e)=>{
      if(e.key === 'Enter' && !e.shiftKey){
        e.preventDefault();
        this.handleSend();
        // close virtual keyboard by blurring
        this.input.blur();
      }
    });

    // voice button
    this.voiceBtn.addEventListener('click', async ()=> {
      if(this.isListening){ // clicking stops and commits interim text
        await this.stopListening(true);
      } else {
        await this.startListening();
      }
    });

    this.updateInputState();
  }
  updateInputState(){
    const txt = this.input.value.trim();
    if(txt.length>0){
      this.sendBtn.classList.remove('disabled');
    } else {
      this.sendBtn.classList.add('disabled');
    }
  }
  addMessage(text, sender='ai'){
    // hide loading indicator first
    this.hideLoading();
    // keep array length
    this.messages.push({text, sender, time: new Date()});
    while(this.messages.length > this.maxMessages) this.messages.shift();
    // rebuild DOM quickly (small number items)
    this.msgList.innerHTML = '';
    if(this.messages.length === 0){
      this.msgList.classList.add('empty');
    } else {
      this.msgList.classList.remove('empty');
    }
    for(const m of this.messages){
      const b = document.createElement('div');
      b.className = 'message-bubble ' + (m.sender==='user' ? 'user' : 'ai');
      const t = document.createElement('div'); t.className='message-text'; t.textContent = m.text;
      const tm = document.createElement('div'); tm.className='message-time'; tm.textContent = m.time.toLocaleTimeString([], {hour:'2-digit', minute:'2-digit'});
      b.appendChild(t); b.appendChild(tm);
      this.msgList.appendChild(b);
      // animate
      requestAnimationFrame(()=> b.classList.add('animate'));
    }
    // scroll last (not scrollable to keep performance)
    // but ensure messages-list visible
    this.msgList.classList.remove('empty');
  }
  showLoading(){
    this.hideLoading();
    const l = document.createElement('div');
    l.id = 'loading-indicator';
    const dot1 = document.createElement('div'); dot1.className='dot';
    const dot2 = document.createElement('div'); dot2.className='dot';
    const dot3 = document.createElement('div'); dot3.className='dot';
    l.appendChild(dot1); l.appendChild(dot2); l.appendChild(dot3);
    this.msgList.appendChild(l);
  }
  hideLoading(){
    const cur = $('loading-indicator');
    if(cur) cur.remove();
  }
  handleSend(){
    const text = this.input.value.trim();
    if(!text) return;
    // stop recognition if active
    if(this.isListening){ this.stopListening(true); }
    // add user message
    this.addMessage(text, 'user');
    this.input.value = '';
    this.updateInputState();
    // show loading and reply after small time (simulate)
    this.showLoading();
    setTimeout(()=>{
      const reply = this.generateReply(text);
      this.addMessage(reply, 'ai');
      // speak reply (but if mic active, we avoid overlap)
      this.speak(reply);
      // set emotion
      this.setEmotionBasedOnText(reply);
    }, 700);
  }
  generateReply(userText){
    // simple mirror with suggestions - replace with AI call if needed
    return `Вы: "${userText}" — я могу помочь ещё?`;
  }

  // ---------------- Speech recognition & mic handling ----------------
  setupSpeechRecognition(){
    const SpeechRec = window.SpeechRecognition || window.webkitSpeechRecognition || null;
    if(!SpeechRec) return;
    this.recognition = new SpeechRec();
    this.recognition.continuous = false;
    this.recognition.interimResults = true; // allow interim so we can commit on stop
    this.recognition.lang = navigator.language || 'ru-RU';
    this.recognition.onresult = (ev)=> this.onSpeechResult(ev);
    this.recognition.onstart = ()=> this.onRecognitionStart();
    this.recognition.onend = ()=> this.onRecognitionEnd();
    this.recognition.onerror = (e)=> this.onRecognitionError(e);
  }

  async initMicPermissionPrompt(){
    // Request mic permission on page open (will show browser prompt)
    try{
      const stream = await navigator.mediaDevices.getUserMedia({audio:true});
      // we only needed permission; stop tracks
      stream.getTracks().forEach(t=>t.stop());
      // update UI state
      this.voiceBtn.classList.remove('disabled');
    }catch(e){
      console.warn('Mic permission denied or not available', e);
      this.voiceBtn.classList.add('disabled');
    }
  }

  async startListening(){
    if(!this.recognition) return;
    // if TTS playing, stop it to avoid loop
    if(this.speechSynth && this.speechSynth.speaking){
      this.speechSynth.cancel();
    }
    try{
      this.recognition.start();
    }catch(e){
      // some browsers throw if started twice
    }
    // start volume monitoring for silence detection
    await this.startVolumeMonitor();
    this.isListening = true;
    this.voiceBtn.setAttribute('aria-pressed','true');
    $('mic-ring').closest = null;
    $('mic-ring').classList.add('listening');
    this.voiceBtn.classList.add('listening');
  }

  async stopListening(commitInterim=false){
    if(!this.recognition) return;
    try{ this.recognition.stop(); }catch(e){}
    this.isListening = false;
    this.voiceBtn.setAttribute('aria-pressed','false');
    $('mic-ring').classList.remove('listening');
    this.voiceBtn.classList.remove('listening');
    // stop audio analysis
    await this.stopVolumeMonitor();
    if(commitInterim && this._lastInterimText){
      // push interim as message
      this.addMessage(this._lastInterimText, 'user');
      // process send automatically (simulate)
      setTimeout(()=> {
        const reply = this.generateReply(this._lastInterimText);
        this.addMessage(reply, 'ai');
        this.speak(reply);
      }, 600);
      this._lastInterimText = '';
    }
  }

  onRecognitionStart(){
    this._lastInterimText = '';
    // when recognition begins, pause any speechSynthesis
    if(this.speechSynth && this.speechSynth.speaking) this.speechSynth.cancel();
  }

  onRecognitionError(e){
    console.warn('Recognition error', e);
    // hide state
    this.isListening = false;
    this.voiceBtn.classList.remove('listening');
    this.stopVolumeMonitor();
  }

  onRecognitionEnd(){
    this.isListening = false;
    this.voiceBtn.classList.remove('listening');
  }

  onSpeechResult(ev){
    let interim = '';
    let final = '';
    for(let i=ev.resultIndex;i<ev.results.length;i++){
      const r = ev.results[i];
      if(r.isFinal) final += r[0].transcript;
      else interim += r[0].transcript;
    }
    // store interim so click outside can commit
    if(interim) {
      this._lastInterimText = interim.trim();
      // show interim in input for feedback
      this.input.value = this._lastInterimText;
      this.updateInputState();
    }
    if(final){
      this._lastInterimText = '';
      this.input.value = '';
      this.addMessage(final.trim(), 'user');
      // simulate reply
      this.showLoading();
      setTimeout(()=>{
        const reply = this.generateReply(final.trim());
        this.addMessage(reply,'ai');
        this.speak(reply);
      },500);
    }
  }

  /* --- Volume monitor: analyze mic levels and auto-stop on silence --- */
  async startVolumeMonitor(){
    if(this.audioContext) return;
    try{
      const constraints = { audio: { echoCancellation:true, noiseSuppression:true } };
      this.micStream = await navigator.mediaDevices.getUserMedia(constraints);
      this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const src = this.audioContext.createMediaStreamSource(this.micStream);
      this.analyser = this.audioContext.createAnalyser();
      this.analyser.fftSize = 512;
      src.connect(this.analyser);
      this._volumeData = new Uint8Array(this.analyser.frequencyBinCount);
      this.lastSoundTime = performance.now();
      this._volumeLoop = setInterval(()=> this._checkVolume(), 120);
    }catch(e){
      console.warn('Volume monitor failed', e);
    }
  }
  async stopVolumeMonitor(){
    if(this._volumeLoop) { clearInterval(this._volumeLoop); this._volumeLoop=null; }
    if(this.micStream) { this.micStream.getTracks().forEach(t=>t.stop()); this.micStream=null; }
    if(this.audioContext && this.audioContext.state !== 'closed') { await this.audioContext.close(); }
    this.audioContext = null; this.analyser = null;
  }
  _checkVolume(){
    if(!this.analyser) return;
    this.analyser.getByteFrequencyData(this._volumeData);
    let sum = 0;
    for(let i=0;i<this._volumeData.length;i++) sum += this._volumeData[i];
    const avg = sum / this._volumeData.length / 255;
    // animate mic based on level
    const mic = $('mic-svg');
    if(mic) mic.style.transform = `scale(${1 + avg*0.28})`;
    if(avg > 0.02){ this.lastSoundTime = performance.now(); }
    // if silent for >1.6s, stop listening automatically
    if(this.isListening && (performance.now() - this.lastSoundTime) > 1600){
      this.stopListening(true);
    }
  }

  // ---------------- TTS ----------------
  speak(text){
    if(!this.speechSynth) return;
    // if currently listening, avoid speaking to prevent loop — stop recognition first
    if(this.isListening){ this.stopListening(); }
    if(this.currentUtterance){
      this.speechSynth.cancel();
      this.currentUtterance = null;
    }
    const u = new SpeechSynthesisUtterance(text);
    u.lang = navigator.language || 'ru-RU';
    u.rate = 1.0; u.pitch = 1.0; u.volume = 1.0;
    u.onstart = ()=> { this.startLipSync(); };
    u.onend = ()=> { this.stopLipSync(); this.currentUtterance = null; };
    u.onerror = ()=> { this.stopLipSync(); this.currentUtterance=null };
    this.currentUtterance = u;
    this.speechSynth.speak(u);
  }
  startLipSync(){
    if(!this.vrm?.expressionManager) return;
    if(this._lipInterval) return;
    this._lipInterval = setInterval(()=>{
      const v = Math.random()*0.6 + 0.2;
      try{ this.vrm.expressionManager.setValue('aa', v); this.vrm.expressionManager.setValue('ih', v*0.6); }catch(e){}
    },70);
  }
  stopLipSync(){
    if(this._lipInterval){ clearInterval(this._lipInterval); this._lipInterval=null; }
    try{ if(this.vrm?.expressionManager){ this.vrm.expressionManager.setValue('aa',0); this.vrm.expressionManager.setValue('ih',0); } }catch(e){}
  }

  // ---------------- Misc UX helpers ----------------
  setEmotionBasedOnText(text){
    if(text.includes('?')) this.setEmotion('surprised',0.6);
    else if(text.includes('!')) this.setEmotion('happy',0.9);
    else this.setEmotion('neutral',1.0);
    // decay
    setTimeout(()=> this.setEmotion('neutral',0.15), 2200);
  }
}

/* ---------------- Initialize companion ---------------- */
const companion = new Companion();
/* Load a sample VRM model (replace with your own). */
companion.loadVRM('https://raw.githubusercontent.com/vrm-c/UniVRM/master/Tests/Models/Alicia_vrm-0.51/AliciaSolid_vrm-0.51.vrm')
  .then(()=> {
    // Say "Привет" on ready
    companion.speak('Привет');
  })
  .catch(()=> {
    // model load not critical
    companion.speak('Привет');
  });

/* Accessibility: click outside while listening should stop and commit */
document.addEventListener('pointerdown', (e)=>{
  // if listening and clicked outside controls, commit interim
  const inControls = e.composedPath().some(n => (n && n.id && (n.id === 'input-container' || n.id === 'voice-button' || n.id === 'chat-input' )));
  if(companion.isListening && !inControls){
    companion.stopListening(true);
  }
}, {passive:true});

/* Prevent default gestures that could interact unexpectedly on mobile */
['gesturestart','gesturechange','gestureend','touchmove'].forEach(ev => {
  window.addEventListener(ev, (e)=> {
    // allow scroll on input area only
    if(e.target && (e.target.id === 'chat-input' || e.target.closest && e.target.closest('#input-container'))) return;
    e.preventDefault();
  }, {passive:false});
});

/* Ensure keyboard adjustments: keep chat anchored — handled by CSS; blur closes keyboard on send already */
</script>
</body>
</html>